{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ffdee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<earthaccess.auth.Auth at 0x200c4acfa10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import earthaccess\n",
    "\n",
    "username = \"ayush.pix\"\n",
    "pw = \"Tumunichdon#pix24\"\n",
    "\n",
    "earthaccess.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f7ce9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter latitude bounds (min_lat,max_lat):\n",
      "Enter longitude bounds (min_lon,max_lon):\n",
      "Enter time period (start_date,end_date) in YYYY-MM-DD:\n",
      "\n",
      "[INFO] Downloading files via wget (you must have Earthdata credentials in .netrc)...\n",
      "Downloading ASTER_AST_08...\n",
      "Downloading MODIS_MOD11A1...\n",
      "Downloading CERES_EBAF...\n",
      "Downloading MOPITT_CO...\n",
      "Downloading MISR_L2...\n",
      "\n",
      "[INFO] All CSVs loaded into DataFrames. Access via the 'dataframes' dictionary.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# ===============================\n",
    "# User Input Section\n",
    "# ===============================\n",
    "print(\"Enter latitude bounds (min_lat,max_lat):\")\n",
    "lat_min, lat_max = map(float, input().split(','))\n",
    "\n",
    "print(\"Enter longitude bounds (min_lon,max_lon):\")\n",
    "lon_min, lon_max = map(float, input().split(','))\n",
    "\n",
    "print(\"Enter time period (start_date,end_date) in YYYY-MM-DD:\")\n",
    "start_date, end_date = input().split(',')\n",
    "\n",
    "output_folder = 'terra_downloads'\n",
    "csv_folder = 'terra_csv_output'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "# ===============================\n",
    "# 1️⃣ Bash download script as Python subprocess\n",
    "# ===============================\n",
    "# Products dictionary: product -> example base URL (LP DAAC / Earthdata)\n",
    "products = {\n",
    "    'ASTER_AST_08': 'https://e4ftl01.cr.usgs.gov/ASTT/AST_08.003',\n",
    "    'MODIS_MOD11A1': 'https://e4ftl01.cr.usgs.gov/MOLT/MOD11A1.061',\n",
    "    'CERES_EBAF': 'https://ceres.larc.nasa.gov/data/EBAF',\n",
    "    'MOPITT_CO': 'https://terra.nasa.gov/data/mopitt-data',\n",
    "    'MISR_L2': 'https://e4ftl01.cr.usgs.gov/MISR/MIL2ASAE.003'\n",
    "}\n",
    "\n",
    "print(\"\\n[INFO] Downloading files via wget (you must have Earthdata credentials in .netrc)...\")\n",
    "\n",
    "for product, url in products.items():\n",
    "    # Here we demonstrate downloading the latest file\n",
    "    # In practice, loop over date range, construct DOY/file paths per product\n",
    "    example_file = f\"{product}_example.hdf\"\n",
    "    wget_cmd = f\"\"\"wget --auth-no-challenge=on -O {output_folder}/{example_file} {url}\"\"\"\n",
    "    print(f\"Downloading {product}...\")\n",
    "    subprocess.run(wget_cmd, shell=True)\n",
    "\n",
    "# ===============================\n",
    "# 2️⃣ Convert downloaded files to CSV\n",
    "# ===============================\n",
    "\"\"\"\n",
    "variable_map = {\n",
    "    'MOD11A1': 'LST_Day_1km',\n",
    "    'ASTER_AST_08': 'Surface_Temperature',\n",
    "    'CERES_EBAF': 'toa_sw_allsky',\n",
    "    'MOPITT_CO': 'CO',\n",
    "    'MISR_L2': 'Radiance'\n",
    "}\n",
    "\"\"\"\n",
    "variable_map = {\n",
    "    'MOD11A1': 'LST_Day_1km'}\n",
    "    \n",
    "data_files = glob(os.path.join(output_folder, '*.[hn]df'))\n",
    "csv_files = []\n",
    "\n",
    "def convert_to_csv(file_path, variable_name, output_dir):\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    if {'lat','lon'}.issubset(ds.coords):\n",
    "        ds_subset = ds.sel(lat=slice(lat_min, lat_max),\n",
    "                           lon=slice(lon_min, lon_max))\n",
    "    else:\n",
    "        ds_subset = ds\n",
    "    df = ds_subset[variable_name].to_dataframe().reset_index()\n",
    "    base_name = os.path.basename(file_path).split('.')[0]\n",
    "    csv_file = os.path.join(output_dir, f\"{base_name}_{variable_name}.csv\")\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    return csv_file\n",
    "\n",
    "for file_path in data_files:\n",
    "    for key in variable_map:\n",
    "        if key in os.path.basename(file_path):\n",
    "            try:\n",
    "                csv_file = convert_to_csv(file_path, variable_map[key], csv_folder)\n",
    "                csv_files.append(csv_file)\n",
    "                print(f\"Converted {file_path} → {csv_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {file_path}: {e}\")\n",
    "\n",
    "# ===============================\n",
    "# 3️⃣ Load CSVs into DataFrames\n",
    "# ===============================\n",
    "dataframes = {}\n",
    "for csv_file in csv_files:\n",
    "    df_name = os.path.basename(csv_file).replace('.csv','')\n",
    "    df = pd.read_csv(csv_file)\n",
    "    dataframes[df_name] = df\n",
    "    print(f\"Loaded CSV {csv_file} into DataFrame '{df_name}'\")\n",
    "\n",
    "print(\"\\n[INFO] All CSVs loaded into DataFrames. Access via the 'dataframes' dictionary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Downloading files from NASA Earthdata...\n",
      "Downloading https://e4ftl01.cr.usgs.gov/ASTT/AST_08.003/ASTER_sample_file.hdf...\n",
      "Failed to download https://e4ftl01.cr.usgs.gov/ASTT/AST_08.003/ASTER_sample_file.hdf: 404 Client Error: Not Found for url: https://e4ftl01.cr.usgs.gov/ASTT/AST_08.003/ASTER_sample_file.hdf\n",
      "Downloading https://e4ftl01.cr.usgs.gov/MOLT/MOD11A1.061/MOD11A1_sample_file.hdf...\n",
      "Failed to download https://e4ftl01.cr.usgs.gov/MOLT/MOD11A1.061/MOD11A1_sample_file.hdf: 404 Client Error: Not Found for url: https://e4ftl01.cr.usgs.gov/MOLT/MOD11A1.061/MOD11A1_sample_file.hdf\n",
      "Downloading https://ceres.larc.nasa.gov/data/EBAF/sample_file.nc...\n",
      "Failed to download https://ceres.larc.nasa.gov/data/EBAF/sample_file.nc: 404 Client Error: Not Found for url: https://ceres.larc.nasa.gov/data/EBAF/sample_file.nc\n",
      "Downloading https://terra.nasa.gov/data/mopitt-data/sample_file.nc...\n",
      "Failed to download https://terra.nasa.gov/data/mopitt-data/sample_file.nc: 404 Client Error: Not Found for url: https://terra.nasa.gov/data/mopitt-data/sample_file.nc\n",
      "\n",
      "[INFO] All CSVs loaded. Access them via the 'dataframes' dictionary.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# ===============================\n",
    "# 1️⃣ User Inputs\n",
    "# ===============================\n",
    "lat_min, lat_max = map(float, input(\"Enter latitude bounds (min_lat,max_lat): \").split(','))\n",
    "lon_min, lon_max = map(float, input(\"Enter longitude bounds (min_lon,max_lon): \").split(','))\n",
    "\n",
    "start_date, end_date = input(\"Enter time period (start_date,end_date) in YYYY-MM-DD: \").split(',')\n",
    "\n",
    "username = input(\"Enter your NASA Earthdata username: \")\n",
    "password = input(\"Enter your NASA Earthdata password: \")\n",
    "\n",
    "output_folder = 'terra_downloads'\n",
    "csv_folder = 'terra_csv_output'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "# ===============================\n",
    "# 2️⃣ Define Product URLs\n",
    "# ===============================\n",
    "# NOTE: You must replace these example URLs with actual HDF/NetCDF file URLs\n",
    "# from LP DAAC / CERES / MOPITT data pool for your date range\n",
    "\"\"\"\n",
    "products = {\n",
    "    'ASTER_AST_08': ['https://e4ftl01.cr.usgs.gov/ASTT/AST_08.003/ASTER_sample_file.hdf'],\n",
    "    'MODIS_MOD11A1': ['https://e4ftl01.cr.usgs.gov/MOLT/MOD11A1.061/MOD11A1_sample_file.hdf'],\n",
    "    'CERES_EBAF': ['https://ceres.larc.nasa.gov/data/EBAF/sample_file.nc'],\n",
    "    'MOPITT_CO': ['https://terra.nasa.gov/data/mopitt-data/sample_file.nc']\n",
    "}\n",
    "\"\"\"\n",
    "products = {\n",
    "    'ASTER_AST_08': ['https://www.earthdata.nasa.gov/data/catalog/lpdaac-ecs-ast-08-003'],\n",
    "    'MODIS_MOD11A1': ['https://e4ftl01.cr.usgs.gov/MOLT/MOD11A1.061/MOD11A1_sample_file.hdf'],\n",
    "    'CERES_EBAF': ['https://ceres.larc.nasa.gov/data/EBAF/sample_file.nc'],\n",
    "    'MOPITT_CO': ['https://terra.nasa.gov/data/mopitt-data/sample_file.nc']\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# 3️⃣ Download Files with Requests\n",
    "# ===============================\n",
    "print(\"\\n[INFO] Downloading files from NASA Earthdata...\")\n",
    "for product, urls in products.items():\n",
    "    for url in urls:\n",
    "        local_filename = os.path.join(output_folder, os.path.basename(url))\n",
    "        if not os.path.exists(local_filename):\n",
    "            print(f\"Downloading {url}...\")\n",
    "            try:\n",
    "                response = requests.get(url, auth=(username, password), stream=True)\n",
    "                response.raise_for_status()\n",
    "                with open(local_filename, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                print(f\"Saved: {local_filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {url}: {e}\")\n",
    "        else:\n",
    "            print(f\"File already exists: {local_filename}\")\n",
    "\n",
    "# ===============================\n",
    "# 4️⃣ Convert HDF/NetCDF to CSV\n",
    "# ===============================\n",
    "# Map product names to variable names\n",
    "variable_map = {\n",
    "    'MOD11A1': 'LST_Day_1km',\n",
    "    'ASTER_AST_08': 'Surface_Temperature',\n",
    "    'CERES_EBAF': 'toa_sw_allsky',\n",
    "    'MOPITT_CO': 'CO'\n",
    "}\n",
    "\n",
    "def convert_to_csv(file_path, variable_name, output_dir):\n",
    "    try:\n",
    "        ds = xr.open_dataset(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Cannot open {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Subset by lat/lon if available\n",
    "    if {'lat','lon'}.issubset(ds.coords):\n",
    "        ds_subset = ds.sel(lat=slice(lat_min, lat_max),\n",
    "                           lon=slice(lon_min, lon_max))\n",
    "    else:\n",
    "        ds_subset = ds\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    try:\n",
    "        df = ds_subset[variable_name].to_dataframe().reset_index()\n",
    "    except Exception as e:\n",
    "        print(f\"Cannot extract variable {variable_name} from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    base_name = os.path.basename(file_path).split('.')[0]\n",
    "    csv_file = os.path.join(output_dir, f\"{base_name}_{variable_name}.csv\")\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    return csv_file\n",
    "\n",
    "# Process all downloaded files\n",
    "data_files = glob(os.path.join(output_folder, '*.[hn]df'))\n",
    "csv_files = []\n",
    "for file_path in data_files:\n",
    "    for key in variable_map:\n",
    "        if key in os.path.basename(file_path):\n",
    "            csv_file = convert_to_csv(file_path, variable_map[key], csv_folder)\n",
    "            if csv_file:\n",
    "                csv_files.append(csv_file)\n",
    "                print(f\"Converted {file_path} → {csv_file}\")\n",
    "\n",
    "# ===============================\n",
    "# 5️⃣ Load CSVs into Pandas DataFrames\n",
    "# ===============================\n",
    "dataframes = {}\n",
    "for csv_file in csv_files:\n",
    "    df_name = os.path.basename(csv_file).replace('.csv','')\n",
    "    df = pd.read_csv(csv_file)\n",
    "    dataframes[df_name] = df\n",
    "    print(f\"Loaded CSV {csv_file} into DataFrame '{df_name}'\")\n",
    "\n",
    "print(\"\\n[INFO] All CSVs loaded. Access them via the 'dataframes' dictionary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f2f772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (2.3.3)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (25.0)\n",
      "Collecting pillow<12,>=7.1.0 (from streamlit)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting protobuf<7,>=3.20 (from streamlit)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (4.15.0)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting jinja2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading markupsafe-3.0.3-cp313-cp313-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.27.1-cp313-cp313-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 4.5/10.1 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.1 MB 23.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 21.2 MB/s  0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 731.2/731.2 kB 14.7 MB/s  0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 5.0/7.0 MB 23.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 20.8 MB/s  0:00:00\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 4.2/6.9 MB 20.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 18.5 MB/s  0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading markupsafe-3.0.3-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading narwhals-2.6.0-py3-none-any.whl (408 kB)\n",
      "Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl (26.1 MB)\n",
      "   ---------------------------------------- 0.0/26.1 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 3.9/26.1 MB 19.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.1/26.1 MB 19.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 12.3/26.1 MB 20.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.0/26.1 MB 20.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.8/26.1 MB 20.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.1 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.1/26.1 MB 20.0 MB/s  0:00:01\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.1-cp313-cp313-win_amd64.whl (232 kB)\n",
      "Installing collected packages: watchdog, toml, smmap, rpds-py, pyarrow, protobuf, pillow, narwhals, MarkupSafe, click, cachetools, blinker, referencing, jinja2, gitdb, pydeck, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "\n",
      "   ----------------------------------------  0/21 [watchdog]\n",
      "   ----------------------------------------  0/21 [watchdog]\n",
      "   ----------------------------------------  0/21 [watchdog]\n",
      "   ----------------------------------------  0/21 [watchdog]\n",
      "   ----------------------------------------  0/21 [watchdog]\n",
      "   ----------------------------------------  0/21 [watchdog]\n",
      "   ----------------------------------------  0/21 [watchdog]\n",
      "   ----------------------------------------  0/21 [watchdog]\n",
      "   ----------------------------------------  0/21 [watchdog]\n",
      "   - --------------------------------------  1/21 [toml]\n",
      "   --- ------------------------------------  2/21 [smmap]\n",
      "   --- ------------------------------------  2/21 [smmap]\n",
      "   ----- ----------------------------------  3/21 [rpds-py]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   ------- --------------------------------  4/21 [pyarrow]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   --------- ------------------------------  5/21 [protobuf]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ----------- ----------------------------  6/21 [pillow]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ------------- --------------------------  7/21 [narwhals]\n",
      "   ----------------- ----------------------  9/21 [click]\n",
      "   ----------------- ----------------------  9/21 [click]\n",
      "   ----------------- ----------------------  9/21 [click]\n",
      "   ----------------- ----------------------  9/21 [click]\n",
      "   ----------------- ----------------------  9/21 [click]\n",
      "   ------------------- -------------------- 10/21 [cachetools]\n",
      "   -------------------- ------------------- 11/21 [blinker]\n",
      "   ---------------------- ----------------- 12/21 [referencing]\n",
      "   ---------------------- ----------------- 12/21 [referencing]\n",
      "   ------------------------ --------------- 13/21 [jinja2]\n",
      "   ------------------------ --------------- 13/21 [jinja2]\n",
      "   ------------------------ --------------- 13/21 [jinja2]\n",
      "   ------------------------ --------------- 13/21 [jinja2]\n",
      "   ------------------------ --------------- 13/21 [jinja2]\n",
      "   ------------------------ --------------- 13/21 [jinja2]\n",
      "   -------------------------- ------------- 14/21 [gitdb]\n",
      "   -------------------------- ------------- 14/21 [gitdb]\n",
      "   -------------------------- ------------- 14/21 [gitdb]\n",
      "   -------------------------- ------------- 14/21 [gitdb]\n",
      "   ---------------------------- ----------- 15/21 [pydeck]\n",
      "   ---------------------------- ----------- 15/21 [pydeck]\n",
      "   ---------------------------- ----------- 15/21 [pydeck]\n",
      "   ---------------------------- ----------- 15/21 [pydeck]\n",
      "   ---------------------------- ----------- 15/21 [pydeck]\n",
      "   ---------------------------- ----------- 15/21 [pydeck]\n",
      "   ---------------------------- ----------- 15/21 [pydeck]\n",
      "   -------------------------------- ------- 17/21 [gitpython]\n",
      "   -------------------------------- ------- 17/21 [gitpython]\n",
      "   -------------------------------- ------- 17/21 [gitpython]\n",
      "   -------------------------------- ------- 17/21 [gitpython]\n",
      "   -------------------------------- ------- 17/21 [gitpython]\n",
      "   -------------------------------- ------- 17/21 [gitpython]\n",
      "   -------------------------------- ------- 17/21 [gitpython]\n",
      "   -------------------------------- ------- 17/21 [gitpython]\n",
      "   ---------------------------------- ----- 18/21 [jsonschema]\n",
      "   ---------------------------------- ----- 18/21 [jsonschema]\n",
      "   ---------------------------------- ----- 18/21 [jsonschema]\n",
      "   ---------------------------------- ----- 18/21 [jsonschema]\n",
      "   ---------------------------------- ----- 18/21 [jsonschema]\n",
      "   ---------------------------------- ----- 18/21 [jsonschema]\n",
      "   ---------------------------------- ----- 18/21 [jsonschema]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   ------------------------------------ --- 19/21 [altair]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   -------------------------------------- - 20/21 [streamlit]\n",
      "   ---------------------------------------- 21/21 [streamlit]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 altair-5.5.0 blinker-1.9.0 cachetools-6.2.0 click-8.3.0 gitdb-4.0.12 gitpython-3.1.45 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 narwhals-2.6.0 pillow-11.3.0 protobuf-6.32.1 pyarrow-21.0.0 pydeck-0.9.1 referencing-0.36.2 rpds-py-0.27.1 smmap-5.0.2 streamlit-1.50.0 toml-0.10.2 watchdog-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f2aa51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 17:37:29.917 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:29.919 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:29.919 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2025-10-04 17:37:29.920 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:29.920 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:29.922 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:29.922 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.299 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\ayush\\AppData\\Roaming\\Python\\Python313\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-10-04 17:37:30.300 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.301 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.301 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.301 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.302 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.302 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.303 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.303 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.304 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.304 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.306 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.306 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.307 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.307 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.308 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.308 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.308 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.309 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.311 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.315 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.317 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.322 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.322 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.324 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.325 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.327 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.328 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.328 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.329 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 17:37:30.331 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1️⃣ Page configuration\n",
    "# --------------------------------------------------\n",
    "st.set_page_config(page_title=\"Rice Growth Demo\", layout=\"wide\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2️⃣ Session state to store inputs\n",
    "# --------------------------------------------------\n",
    "if \"page\" not in st.session_state:\n",
    "    st.session_state.page = 1\n",
    "\n",
    "def next_page():\n",
    "    st.session_state.page += 1\n",
    "\n",
    "def prev_page():\n",
    "    st.session_state.page -= 1\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3️⃣ Page 1: Select Location\n",
    "# --------------------------------------------------\n",
    "if st.session_state.page == 1:\n",
    "    st.title(\"🌍 Select Location\")\n",
    "    st.write(\"Please select your region and specify latitude/longitude bounds.\")\n",
    "\n",
    "    region = st.text_input(\"Region / City Name\", placeholder=\"e.g., Hanoi, Vietnam\")\n",
    "    lat_min = st.number_input(\"Minimum Latitude\", value=10.0)\n",
    "    lat_max = st.number_input(\"Maximum Latitude\", value=20.0)\n",
    "    lon_min = st.number_input(\"Minimum Longitude\", value=100.0)\n",
    "    lon_max = st.number_input(\"Maximum Longitude\", value=110.0)\n",
    "\n",
    "    st.write(\"---\")\n",
    "    st.button(\"Next ➡️\", on_click=next_page)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4️⃣ Page 2: Select Crop\n",
    "# --------------------------------------------------\n",
    "elif st.session_state.page == 2:\n",
    "    st.title(\"🌾 Select Crop\")\n",
    "    st.write(\"Choose the crop you want to analyze.\")\n",
    "    crop = st.selectbox(\"Select Crop\", [\"Rice\"], index=0)\n",
    "    st.write(f\"✅ You selected: **{crop}**\")\n",
    "\n",
    "    st.write(\"---\")\n",
    "    col1, col2 = st.columns(2)\n",
    "    col1.button(\"⬅️ Back\", on_click=prev_page)\n",
    "    col2.button(\"Next ➡️\", on_click=next_page)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5️⃣ Page 3: Compare Ideal vs Local Conditions\n",
    "# --------------------------------------------------\n",
    "elif st.session_state.page == 3:\n",
    "    st.title(\"🌦️ Compare Growing Conditions for Rice\")\n",
    "\n",
    "    st.write(\"Below is a comparison between **ideal conditions for rice** and your region's **average annual conditions**.\")\n",
    "\n",
    "    # Ideal rice growing conditions\n",
    "    ideal = {\n",
    "        \"Parameter\": [\n",
    "            \"Temperature (°C)\",\n",
    "            \"Annual Rainfall (mm)\",\n",
    "            \"Soil Type\",\n",
    "            \"Soil pH\",\n",
    "            \"Sunlight (hours/day)\",\n",
    "            \"Humidity (%)\",\n",
    "            \"Altitude (m)\"\n",
    "        ],\n",
    "        \"Ideal for Rice\": [\n",
    "            \"20–35\",\n",
    "            \"1000–2000\",\n",
    "            \"Alluvial / Clay loam\",\n",
    "            \"5.5–7.0\",\n",
    "            \"4–6\",\n",
    "            \"70–80\",\n",
    "            \"0–1500\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Dummy “local” example data (in a real app, load from dataset or API)\n",
    "    local = {\n",
    "        \"Parameter\": [\n",
    "            \"Temperature (°C)\",\n",
    "            \"Annual Rainfall (mm)\",\n",
    "            \"Soil Type\",\n",
    "            \"Soil pH\",\n",
    "            \"Sunlight (hours/day)\",\n",
    "            \"Humidity (%)\",\n",
    "            \"Altitude (m)\"\n",
    "        ],\n",
    "        \"Your Location (Average)\": [\n",
    "            \"29\",\n",
    "            \"1450\",\n",
    "            \"Clay loam\",\n",
    "            \"6.2\",\n",
    "            \"5.2\",\n",
    "            \"75\",\n",
    "            \"210\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_ideal = pd.DataFrame(ideal)\n",
    "    df_local = pd.DataFrame(local)\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        st.subheader(\"✅ Ideal Rice Conditions\")\n",
    "        st.dataframe(df_ideal, use_container_width=True)\n",
    "\n",
    "    with col2:\n",
    "        st.subheader(\"📍 Your Location\")\n",
    "        st.dataframe(df_local, use_container_width=True)\n",
    "\n",
    "    st.write(\"---\")\n",
    "    st.button(\"⬅️ Back\", on_click=prev_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f7eccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.50.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.2.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (2.3.3)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.32.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit pandas requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "173e8397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 21:31:24.453 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.458 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.459 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.461 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.465 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.467 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.470 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.471 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.473 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.473 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.474 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.475 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.476 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.478 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.478 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.480 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.483 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.484 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.485 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.486 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.488 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.491 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.493 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.494 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.494 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.883 Please replace `use_container_width` with `width`.\n",
      "\n",
      "`use_container_width` will be removed after 2025-12-31.\n",
      "\n",
      "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
      "2025-10-04 21:31:24.948 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.949 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:24.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_1004\\3181215317.py:45: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df.index = pd.to_datetime(df.index)\n",
      "2025-10-04 21:31:33.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:33.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:33.375 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:33.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:33.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:33.380 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:33.381 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:33.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:33.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:31:33.384 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'avg_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 112\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mSoil\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m param \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAltitude\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m param:\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# skip those since we don't have data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m local_avg = \u001b[43mavg_data\u001b[49m.get(param.replace(\u001b[33m\"\u001b[39m\u001b[33mAnnual \u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33m(mm)\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip(), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_avg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (ideal_min <= local_avg <= ideal_max):\n\u001b[32m    114\u001b[39m     recommendations.append(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'avg_data' is not defined"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import requests\n",
    "import plotly.express as px\n",
    "\n",
    "st.set_page_config(page_title=\"Crop Growth Suitability Demo\", layout=\"wide\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Crop database — easy to extend later\n",
    "# ----------------------------------------------------------------\n",
    "CROP_CONDITIONS = {\n",
    "    \"Rice\": {\n",
    "        \"Temperature (°C)\": (20, 35),\n",
    "        \"Annual Rainfall (mm)\": (1000, 2000),\n",
    "        \"Soil pH\": (5.5, 7.0),\n",
    "        \"Sunlight (MJ/m²/day)\": (14, 20),\n",
    "        \"Relative Humidity (%)\": (70, 80),\n",
    "        \"Altitude (m)\": (0, 1500),\n",
    "    },\n",
    "    \"Wheat\": {\n",
    "        \"Temperature (°C)\": (10, 25),\n",
    "        \"Annual Rainfall (mm)\": (500, 1200),\n",
    "        \"Soil pH\": (6.0, 7.5),\n",
    "        \"Sunlight (MJ/m²/day)\": (10, 16),\n",
    "        \"Relative Humidity (%)\": (50, 70),\n",
    "        \"Altitude (m)\": (0, 3000),\n",
    "    },\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# NASA POWER API functions\n",
    "# ----------------------------------------------------------------\n",
    "def get_climate_data(lat, lon):\n",
    "    \"\"\"Fetch monthly climatology for multiple parameters from NASA POWER.\"\"\"\n",
    "    url = (\n",
    "        f\"https://power.larc.nasa.gov/api/temporal/monthly/point?\"\n",
    "        f\"parameters=T2M,PRECTOTCORR,RH2M,ALLSKY_SFC_SW_DWN\"\n",
    "        f\"&community=AG&longitude={lon}&latitude={lat}&format=JSON&start=2015&end=2024\"\n",
    "    )\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()[\"properties\"][\"parameter\"]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"T2M\": \"Temperature (°C)\",\n",
    "            \"PRECTOTCORR\": \"Rainfall (mm)\",\n",
    "            \"RH2M\": \"Humidity (%)\",\n",
    "            \"ALLSKY_SFC_SW_DWN\": \"Sunlight (MJ/m²/day)\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# GUI Layout\n",
    "# ----------------------------------------------------------------\n",
    "st.title(\"🌾 Crop Growth Suitability Explorer\")\n",
    "st.write(\"Analyze if your location is suitable for growing different crops based on NASA POWER climate data.\")\n",
    "\n",
    "# Input controls\n",
    "st.sidebar.header(\"User Input\")\n",
    "lat = st.sidebar.number_input(\"Latitude\", value=22.0, format=\"%.2f\")\n",
    "lon = st.sidebar.number_input(\"Longitude\", value=88.0, format=\"%.2f\")\n",
    "crop = st.sidebar.selectbox(\"Select Crop\", list(CROP_CONDITIONS.keys()))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Main content layout\n",
    "# ----------------------------------------------------------------\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "# Ideal conditions\n",
    "with col1:\n",
    "    st.subheader(f\"✅ Ideal Conditions for {crop}\")\n",
    "    crop_df = pd.DataFrame(\n",
    "        [(k, f\"{v[0]}–{v[1]}\") for k, v in CROP_CONDITIONS[crop].items()],\n",
    "        columns=[\"Parameter\", \"Ideal Range\"],\n",
    "    )\n",
    "    st.dataframe(crop_df, use_container_width=True)\n",
    "\n",
    "# Fetch and show actual data\n",
    "with col2:\n",
    "    st.subheader(\"📍 Local Climate Data (NASA POWER)\")\n",
    "    try:\n",
    "        df = get_climate_data(lat, lon)\n",
    "        avg_data = df.mean().round(2)\n",
    "        min_data = df.min().round(2)\n",
    "        max_data = df.max().round(2)\n",
    "\n",
    "        stats = pd.DataFrame(\n",
    "            {\"Min\": min_data, \"Avg\": avg_data, \"Max\": max_data}\n",
    "        ).reset_index()\n",
    "        stats.rename(columns={\"index\": \"Parameter\"}, inplace=True)\n",
    "        st.dataframe(stats, use_container_width=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error fetching data: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Recommendation logic\n",
    "# ----------------------------------------------------------------\n",
    "st.write(\"---\")\n",
    "st.subheader(\"🌱 Recommendation\")\n",
    "\n",
    "recommendations = []\n",
    "for param, (ideal_min, ideal_max) in CROP_CONDITIONS[crop].items():\n",
    "    if \"Soil\" in param or \"Altitude\" in param:\n",
    "        continue  # skip those since we don't have data\n",
    "    local_avg = avg_data.get(param.replace(\"Annual \", \"\").replace(\"(mm)\", \"\").strip(), None)\n",
    "    if local_avg is not None and (ideal_min <= local_avg <= ideal_max):\n",
    "        recommendations.append(True)\n",
    "    else:\n",
    "        recommendations.append(False)\n",
    "\n",
    "suitability = \"✅ YES — Suitable for growing!\" if all(recommendations) else \"❌ NO — Not ideal climate\"\n",
    "st.markdown(f\"### {suitability}\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Plot trends\n",
    "# ----------------------------------------------------------------\n",
    "st.write(\"---\")\n",
    "st.subheader(\"📊 Climate Trends at Your Location\")\n",
    "\n",
    "fig = px.line(df, x=df.index, y=df.columns, title=\"Monthly Climate Trends (2015–2024)\")\n",
    "st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "st.caption(\"Data Source: NASA POWER API | Visualization by Streamlit & Plotly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45d19ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 21:32:28.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.360 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.363 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.366 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.367 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.369 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.372 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.374 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.375 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.377 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.378 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.380 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.381 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.381 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.385 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.386 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.387 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.389 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.395 Please replace `use_container_width` with `width`.\n",
      "\n",
      "`use_container_width` will be removed after 2025-12-31.\n",
      "\n",
      "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
      "2025-10-04 21:32:28.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.399 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.399 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:28.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_1004\\1818416294.py:45: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df.index = pd.to_datetime(df.index)\n",
      "2025-10-04 21:32:36.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:36.799 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:36.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:36.807 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:36.808 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-04 21:32:36.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import requests\n",
    "import plotly.express as px\n",
    "\n",
    "st.set_page_config(page_title=\"Crop Growth Suitability Demo\", layout=\"wide\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Crop database — easy to extend later\n",
    "# ----------------------------------------------------------------\n",
    "CROP_CONDITIONS = {\n",
    "    \"Rice\": {\n",
    "        \"Temperature (°C)\": (20, 35),\n",
    "        \"Annual Rainfall (mm)\": (1000, 2000),\n",
    "        \"Soil pH\": (5.5, 7.0),\n",
    "        \"Sunlight (MJ/m²/day)\": (14, 20),\n",
    "        \"Relative Humidity (%)\": (70, 80),\n",
    "        \"Altitude (m)\": (0, 1500),\n",
    "    },\n",
    "    \"Wheat\": {\n",
    "        \"Temperature (°C)\": (10, 25),\n",
    "        \"Annual Rainfall (mm)\": (500, 1200),\n",
    "        \"Soil pH\": (6.0, 7.5),\n",
    "        \"Sunlight (MJ/m²/day)\": (10, 16),\n",
    "        \"Relative Humidity (%)\": (50, 70),\n",
    "        \"Altitude (m)\": (0, 3000),\n",
    "    },\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# NASA POWER API functions\n",
    "# ----------------------------------------------------------------\n",
    "def get_climate_data(lat, lon):\n",
    "    \"\"\"Fetch monthly climatology for multiple parameters from NASA POWER.\"\"\"\n",
    "    url = (\n",
    "        f\"https://power.larc.nasa.gov/api/temporal/monthly/point?\"\n",
    "        f\"parameters=T2M,PRECTOTCORR,RH2M,ALLSKY_SFC_SW_DWN\"\n",
    "        f\"&community=AG&longitude={lon}&latitude={lat}&format=JSON&start=2015&end=2024\"\n",
    "    )\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()[\"properties\"][\"parameter\"]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"T2M\": \"Temperature (°C)\",\n",
    "            \"PRECTOTCORR\": \"Annual Rainfall (mm)\",\n",
    "            \"RH2M\": \"Relative Humidity (%)\",\n",
    "            \"ALLSKY_SFC_SW_DWN\": \"Sunlight (MJ/m²/day)\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# GUI Layout\n",
    "# ----------------------------------------------------------------\n",
    "st.title(\"🌾 Crop Growth Suitability Explorer\")\n",
    "st.write(\"Analyze if your location is suitable for growing different crops based on NASA POWER climate data.\")\n",
    "\n",
    "# Input controls\n",
    "st.sidebar.header(\"User Input\")\n",
    "lat = st.sidebar.number_input(\"Latitude\", value=22.0, format=\"%.2f\")\n",
    "lon = st.sidebar.number_input(\"Longitude\", value=88.0, format=\"%.2f\")\n",
    "crop = st.sidebar.selectbox(\"Select Crop\", list(CROP_CONDITIONS.keys()))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Main content layout\n",
    "# ----------------------------------------------------------------\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "# Ideal conditions\n",
    "with col1:\n",
    "    st.subheader(f\"✅ Ideal Conditions for {crop}\")\n",
    "    crop_df = pd.DataFrame(\n",
    "        [(k, f\"{v[0]}–{v[1]}\") for k, v in CROP_CONDITIONS[crop].items()],\n",
    "        columns=[\"Parameter\", \"Ideal Range\"],\n",
    "    )\n",
    "    st.dataframe(crop_df, use_container_width=True)\n",
    "\n",
    "# Fetch and show actual data\n",
    "with col2:\n",
    "    st.subheader(\"📍 Local Climate Data (NASA POWER)\")\n",
    "    df, avg_data, min_data, max_data = None, None, None, None\n",
    "    try:\n",
    "        df = get_climate_data(lat, lon)\n",
    "        avg_data = df.mean().round(2)\n",
    "        min_data = df.min().round(2)\n",
    "        max_data = df.max().round(2)\n",
    "\n",
    "        stats = pd.DataFrame(\n",
    "            {\"Min\": min_data, \"Avg\": avg_data, \"Max\": max_data}\n",
    "        ).reset_index()\n",
    "        stats.rename(columns={\"index\": \"Parameter\"}, inplace=True)\n",
    "        st.dataframe(stats, use_container_width=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"⚠️ Error fetching data: {e}\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Recommendation logic (only if data fetched)\n",
    "# ----------------------------------------------------------------\n",
    "if avg_data is not None:\n",
    "    st.write(\"---\")\n",
    "    st.subheader(\"🌱 Recommendation\")\n",
    "\n",
    "    recommendations = []\n",
    "    for param, (ideal_min, ideal_max) in CROP_CONDITIONS[crop].items():\n",
    "        # Skip unmeasured parameters\n",
    "        if param not in avg_data:\n",
    "            continue\n",
    "        local_avg = avg_data[param]\n",
    "        if ideal_min <= local_avg <= ideal_max:\n",
    "            recommendations.append(True)\n",
    "        else:\n",
    "            recommendations.append(False)\n",
    "\n",
    "    suitability = (\n",
    "        \"✅ YES — Suitable for growing!\"\n",
    "        if all(recommendations)\n",
    "        else \"❌ NO — Not ideal climate\"\n",
    "    )\n",
    "    st.markdown(f\"### {suitability}\")\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # Plot trends\n",
    "    # ----------------------------------------------------------------\n",
    "    st.write(\"---\")\n",
    "    st.subheader(\"📊 Climate Trends at Your Location\")\n",
    "    fig = px.line(df, x=df.index, y=df.columns, title=\"Monthly Climate Trends (2015–2024)\")\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    st.caption(\"Data Source: NASA POWER API | Visualization by Streamlit & Plotly\")\n",
    "else:\n",
    "    st.info(\"👆 Enter coordinates to fetch and visualize local climate data.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
